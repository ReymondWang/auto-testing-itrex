{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef663a5-3dee-468e-9ec3-435bcddb6757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/itrex-classic/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n",
      "2024-05-05 18:02:05,626 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: ../../pretrained-model/bge-base-zh-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create retrieval plugin instance...\n",
      "plugin parameters:  {'embedding_model': '../../pretrained-model/bge-base-zh-v1.5', 'input_path': '../data/sample.jsonl'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:02:06,348 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2024-05-05 18:02:06,354 - root - INFO - The parsing for the uploaded files is finished.\n",
      "2024-05-05 18:02:06,355 - root - INFO - The format of parsed documents is transferred.\n",
      "2024-05-05 18:02:06,363 - chromadb.telemetry.product.posthog - INFO - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c060735e0e4ca5a67bb85bc395d75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:02:06,963 - root - INFO - The retriever is successfully built.\n",
      "2024-05-05 18:02:07,166 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting eos_token is not supported, use the default one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ../../pretrained-model/chatglm3-6b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:02:07,168 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting pad_token is not supported, use the default one.\n",
      "2024-05-05 18:02:07,170 - transformers_modules.chatglm3_6b.tokenization_chatglm - WARNING - Setting unk_token is not supported, use the default one.\n",
      "2024-05-05 18:02:07 [INFO] Applying Weight Only Quantization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b134a699a64a5c875b37e7d63e84d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:03:02 [INFO] Start auto tuning.\n",
      "2024-05-05 18:03:02 [INFO] Quantize model without tuning!\n",
      "2024-05-05 18:03:02 [INFO] Quantize the model with default configuration without evaluating the model.                To perform the tuning process, please either provide an eval_func or provide an                    eval_dataloader an eval_metric.\n",
      "2024-05-05 18:03:02 [INFO] Adaptor has 5 recipes.\n",
      "2024-05-05 18:03:02 [INFO] 0 recipes specified by user.\n",
      "2024-05-05 18:03:02 [INFO] 3 recipes require future tuning.\n",
      "2024-05-05 18:03:02 [INFO] *** Initialize auto tuning\n",
      "2024-05-05 18:03:02 [INFO] {\n",
      "2024-05-05 18:03:02 [INFO]     'PostTrainingQuantConfig': {\n",
      "2024-05-05 18:03:02 [INFO]         'AccuracyCriterion': {\n",
      "2024-05-05 18:03:02 [INFO]             'criterion': 'relative',\n",
      "2024-05-05 18:03:02 [INFO]             'higher_is_better': True,\n",
      "2024-05-05 18:03:02 [INFO]             'tolerable_loss': 0.01,\n",
      "2024-05-05 18:03:02 [INFO]             'absolute': None,\n",
      "2024-05-05 18:03:02 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f01f0e6dba0>>,\n",
      "2024-05-05 18:03:02 [INFO]             'relative': 0.01\n",
      "2024-05-05 18:03:02 [INFO]         },\n",
      "2024-05-05 18:03:02 [INFO]         'approach': 'post_training_weight_only',\n",
      "2024-05-05 18:03:02 [INFO]         'backend': 'default',\n",
      "2024-05-05 18:03:02 [INFO]         'calibration_sampling_size': [\n",
      "2024-05-05 18:03:02 [INFO]             100\n",
      "2024-05-05 18:03:02 [INFO]         ],\n",
      "2024-05-05 18:03:02 [INFO]         'device': 'cpu',\n",
      "2024-05-05 18:03:02 [INFO]         'diagnosis': False,\n",
      "2024-05-05 18:03:02 [INFO]         'domain': 'auto',\n",
      "2024-05-05 18:03:02 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2024-05-05 18:03:02 [INFO]         'excluded_precisions': [\n",
      "2024-05-05 18:03:02 [INFO]         ],\n",
      "2024-05-05 18:03:02 [INFO]         'framework': 'pytorch_fx',\n",
      "2024-05-05 18:03:02 [INFO]         'inputs': [\n",
      "2024-05-05 18:03:02 [INFO]         ],\n",
      "2024-05-05 18:03:02 [INFO]         'model_name': '',\n",
      "2024-05-05 18:03:02 [INFO]         'ni_workload_name': 'quantization',\n",
      "2024-05-05 18:03:02 [INFO]         'op_name_dict': {\n",
      "2024-05-05 18:03:02 [INFO]             '.*lm_head': {\n",
      "2024-05-05 18:03:02 [INFO]                 'weight': {\n",
      "2024-05-05 18:03:02 [INFO]                     'dtype': [\n",
      "2024-05-05 18:03:02 [INFO]                         'fp32'\n",
      "2024-05-05 18:03:02 [INFO]                     ]\n",
      "2024-05-05 18:03:02 [INFO]                 }\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             '.*output_layer': {\n",
      "2024-05-05 18:03:02 [INFO]                 'weight': {\n",
      "2024-05-05 18:03:02 [INFO]                     'dtype': [\n",
      "2024-05-05 18:03:02 [INFO]                         'fp32'\n",
      "2024-05-05 18:03:02 [INFO]                     ]\n",
      "2024-05-05 18:03:02 [INFO]                 }\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             '.*embed_out': {\n",
      "2024-05-05 18:03:02 [INFO]                 'weight': {\n",
      "2024-05-05 18:03:02 [INFO]                     'dtype': [\n",
      "2024-05-05 18:03:02 [INFO]                         'fp32'\n",
      "2024-05-05 18:03:02 [INFO]                     ]\n",
      "2024-05-05 18:03:02 [INFO]                 }\n",
      "2024-05-05 18:03:02 [INFO]             }\n",
      "2024-05-05 18:03:02 [INFO]         },\n",
      "2024-05-05 18:03:02 [INFO]         'op_type_dict': {\n",
      "2024-05-05 18:03:02 [INFO]             '.*': {\n",
      "2024-05-05 18:03:02 [INFO]                 'weight': {\n",
      "2024-05-05 18:03:02 [INFO]                     'bits': [\n",
      "2024-05-05 18:03:02 [INFO]                         4\n",
      "2024-05-05 18:03:02 [INFO]                     ],\n",
      "2024-05-05 18:03:02 [INFO]                     'dtype': [\n",
      "2024-05-05 18:03:02 [INFO]                         'int4'\n",
      "2024-05-05 18:03:02 [INFO]                     ],\n",
      "2024-05-05 18:03:02 [INFO]                     'group_size': [\n",
      "2024-05-05 18:03:02 [INFO]                         32\n",
      "2024-05-05 18:03:02 [INFO]                     ],\n",
      "2024-05-05 18:03:02 [INFO]                     'scheme': [\n",
      "2024-05-05 18:03:02 [INFO]                         'sym'\n",
      "2024-05-05 18:03:02 [INFO]                     ],\n",
      "2024-05-05 18:03:02 [INFO]                     'algorithm': [\n",
      "2024-05-05 18:03:02 [INFO]                         'RTN'\n",
      "2024-05-05 18:03:02 [INFO]                     ]\n",
      "2024-05-05 18:03:02 [INFO]                 }\n",
      "2024-05-05 18:03:02 [INFO]             }\n",
      "2024-05-05 18:03:02 [INFO]         },\n",
      "2024-05-05 18:03:02 [INFO]         'outputs': [\n",
      "2024-05-05 18:03:02 [INFO]         ],\n",
      "2024-05-05 18:03:02 [INFO]         'quant_format': 'default',\n",
      "2024-05-05 18:03:02 [INFO]         'quant_level': 'auto',\n",
      "2024-05-05 18:03:02 [INFO]         'recipes': {\n",
      "2024-05-05 18:03:02 [INFO]             'smooth_quant': False,\n",
      "2024-05-05 18:03:02 [INFO]             'smooth_quant_args': {\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'layer_wise_quant': False,\n",
      "2024-05-05 18:03:02 [INFO]             'layer_wise_quant_args': {\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'fast_bias_correction': False,\n",
      "2024-05-05 18:03:02 [INFO]             'weight_correction': False,\n",
      "2024-05-05 18:03:02 [INFO]             'gemm_to_matmul': True,\n",
      "2024-05-05 18:03:02 [INFO]             'graph_optimization_level': None,\n",
      "2024-05-05 18:03:02 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2024-05-05 18:03:02 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2024-05-05 18:03:02 [INFO]             'pre_post_process_quantization': True,\n",
      "2024-05-05 18:03:02 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2024-05-05 18:03:02 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2024-05-05 18:03:02 [INFO]             ],\n",
      "2024-05-05 18:03:02 [INFO]             'dedicated_qdq_pair': False,\n",
      "2024-05-05 18:03:02 [INFO]             'rtn_args': {\n",
      "2024-05-05 18:03:02 [INFO]                 'enable_full_range': True,\n",
      "2024-05-05 18:03:02 [INFO]                 'enable_mse_search': False\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'awq_args': {\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'gptq_args': {\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'teq_args': {\n",
      "2024-05-05 18:03:02 [INFO]             },\n",
      "2024-05-05 18:03:02 [INFO]             'autoround_args': {\n",
      "2024-05-05 18:03:02 [INFO]             }\n",
      "2024-05-05 18:03:02 [INFO]         },\n",
      "2024-05-05 18:03:02 [INFO]         'reduce_range': None,\n",
      "2024-05-05 18:03:02 [INFO]         'TuningCriterion': {\n",
      "2024-05-05 18:03:02 [INFO]             'max_trials': 100,\n",
      "2024-05-05 18:03:02 [INFO]             'objective': [\n",
      "2024-05-05 18:03:02 [INFO]                 'performance'\n",
      "2024-05-05 18:03:02 [INFO]             ],\n",
      "2024-05-05 18:03:02 [INFO]             'strategy': 'basic',\n",
      "2024-05-05 18:03:02 [INFO]             'strategy_kwargs': None,\n",
      "2024-05-05 18:03:02 [INFO]             'timeout': 0\n",
      "2024-05-05 18:03:02 [INFO]         },\n",
      "2024-05-05 18:03:02 [INFO]         'use_bf16': True\n",
      "2024-05-05 18:03:02 [INFO]     }\n",
      "2024-05-05 18:03:02 [INFO] }\n",
      "2024-05-05 18:03:02 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-05-05 18:03:02 [INFO] Pass query framework capability elapsed time: 6.49 ms\n",
      "2024-05-05 18:03:02 [INFO] Do not evaluate the baseline and quantize the model with default configuration.\n",
      "2024-05-05 18:03:02 [INFO] Quantize the model with default config.\n",
      "2024-05-05 18:03:02 [INFO] All algorithms to do: {'RTN'}\n",
      "2024-05-05 18:03:02 [INFO] quantizing with the round-to-nearest algorithm\n",
      "2024-05-05 18:03:10 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-05-05 18:03:10 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 18:03:10 [INFO] | Op Type | Total |  A32W4G32 |  FP32  |\n",
      "2024-05-05 18:03:10 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 18:03:10 [INFO] |  Linear |  113  |    112    |   1    |\n",
      "2024-05-05 18:03:10 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 18:03:10 [INFO] Pass quantize model elapsed time: 7968.31 ms\n",
      "2024-05-05 18:03:10 [INFO] Save tuning history to /autodl-fs/data/auto-testing/intel/nc_workspace/2024-05-05_18-01-59/./history.snapshot.\n",
      "2024-05-05 18:03:10 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2024-05-05 18:03:10 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2024-05-05 18:03:10 [INFO] Save deploy yaml to /autodl-fs/data/auto-testing/intel/nc_workspace/2024-05-05_18-01-59/deploy.yaml\n",
      "2024-05-05 18:03:42 [INFO] WeightOnlyQuant done.\n",
      "2024-05-05 18:03:42,397 - root - INFO - Optimized Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from intel_extension_for_transformers.neural_chat import PipelineConfig\n",
    "from intel_extension_for_transformers.neural_chat import build_chatbot\n",
    "from intel_extension_for_transformers.neural_chat import plugins \n",
    "from intel_extension_for_transformers.transformers import RtnConfig\n",
    "from time import time\n",
    "\n",
    "plugins.retrieval.enable=True \n",
    "plugins.retrieval.args['embedding_model'] = \"../../pretrained-model/bge-base-zh-v1.5\" \n",
    "plugins.retrieval.args[\"input_path\"]=\"../data/sample.jsonl\"\n",
    "config = PipelineConfig(\n",
    "    model_name_or_path='../../pretrained-model/chatglm3-6b',\n",
    "    plugins=plugins,\n",
    "    optimization_config=RtnConfig(compute_dtype=\"int8\", weight_dtype=\"int4_fullrange\")\n",
    ")\n",
    "chatbot = build_chatbot(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b6140b-a2f4-4669-b647-1a126cd619c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/itrex-classic/lib/python3.10/site-packages/torch/amp/autocast_mode.py:267: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 时间:17.508034229278564s\n",
      "cnvrg.io 网站是由一个名为CNVRG的神秘组织创建的。关于这个组织的具体信息很难获取，因为它们似乎非常低调。然而，我们可以看到网站上留下的联系信息，其中提到了一个电子邮件地址（[contact@cnvrg.io](mailto:contact@cnvrg.io)），但目前没有其他详细信息来证实这个组织的身份。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=False # disable retrieval\n",
    "\n",
    "st = time()\n",
    "response = chatbot.predict(query=\"cnvrg.io 网站是由谁创建的?\") \n",
    "et = time()\n",
    "\n",
    "print(\"predict 时间:{}s\".format(et-st))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "720d30ad-3e98-4599-a75b-c52b0b150ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ce9128a5a452eacc8310a99a104e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:04:18,815 - root - INFO - Chat with QA Agent.\n",
      "/root/miniconda3/envs/itrex-classic/lib/python3.10/site-packages/torch/amp/autocast_mode.py:267: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 时间:21.835801124572754s\n",
      "抱歉，我无法回答您的问题。根据我的搜索结果，没有找到有关 \"cnvrg.io\" 网站创建者的信息。请提供更多上下文或详细描述，以便我能更好地帮助您。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=True # disable retrieval\n",
    "\n",
    "st = time()\n",
    "response = chatbot.predict(query=\"cnvrg.io 网站是由谁创建的?\") \n",
    "et = time()\n",
    "\n",
    "print(\"predict 时间:{}s\".format(et-st))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "358a06de-8c31-42a9-983e-03bb313659aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a1fd4b9-09c9-4704-9399-64056772049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:53:02,975 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: ../../pretrained-model/bge-base-zh-v1.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create retrieval plugin instance...\n",
      "plugin parameters:  {'embedding_model': '../../pretrained-model/bge-base-zh-v1.5', 'input_path': '../data/sample.jsonl'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:53:03,179 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu\n",
      "2024-05-05 18:53:03,183 - root - INFO - The parsing for the uploaded files is finished.\n",
      "2024-05-05 18:53:03,184 - root - INFO - The format of parsed documents is transferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872897e92c4d4bc88ae2e3be85b0de83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:53:03,355 - root - INFO - The retriever is successfully built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model Intel/neural-chat-7b-v3-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 18:53:05 [INFO] Applying Weight Only Quantization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f63c853c56047fd9ee7ca8266e35e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f90ca767514012a43a048feb8b0d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5c082735924915a4a248ce23b95ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d17a5347b67442e9bcfdf926a119df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:02:45 [INFO] Start auto tuning.\n",
      "2024-05-05 19:02:45 [INFO] Quantize model without tuning!\n",
      "2024-05-05 19:02:45 [INFO] Quantize the model with default configuration without evaluating the model.                To perform the tuning process, please either provide an eval_func or provide an                    eval_dataloader an eval_metric.\n",
      "2024-05-05 19:02:45 [INFO] Adaptor has 5 recipes.\n",
      "2024-05-05 19:02:45 [INFO] 0 recipes specified by user.\n",
      "2024-05-05 19:02:45 [INFO] 3 recipes require future tuning.\n",
      "2024-05-05 19:02:45 [INFO] *** Initialize auto tuning\n",
      "2024-05-05 19:02:45 [INFO] {\n",
      "2024-05-05 19:02:45 [INFO]     'PostTrainingQuantConfig': {\n",
      "2024-05-05 19:02:45 [INFO]         'AccuracyCriterion': {\n",
      "2024-05-05 19:02:45 [INFO]             'criterion': 'relative',\n",
      "2024-05-05 19:02:45 [INFO]             'higher_is_better': True,\n",
      "2024-05-05 19:02:45 [INFO]             'tolerable_loss': 0.01,\n",
      "2024-05-05 19:02:45 [INFO]             'absolute': None,\n",
      "2024-05-05 19:02:45 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x7f01f0e6dba0>>,\n",
      "2024-05-05 19:02:45 [INFO]             'relative': 0.01\n",
      "2024-05-05 19:02:45 [INFO]         },\n",
      "2024-05-05 19:02:45 [INFO]         'approach': 'post_training_weight_only',\n",
      "2024-05-05 19:02:45 [INFO]         'backend': 'default',\n",
      "2024-05-05 19:02:45 [INFO]         'calibration_sampling_size': [\n",
      "2024-05-05 19:02:45 [INFO]             100\n",
      "2024-05-05 19:02:45 [INFO]         ],\n",
      "2024-05-05 19:02:45 [INFO]         'device': 'cpu',\n",
      "2024-05-05 19:02:45 [INFO]         'diagnosis': False,\n",
      "2024-05-05 19:02:45 [INFO]         'domain': 'auto',\n",
      "2024-05-05 19:02:45 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2024-05-05 19:02:45 [INFO]         'excluded_precisions': [\n",
      "2024-05-05 19:02:45 [INFO]         ],\n",
      "2024-05-05 19:02:45 [INFO]         'framework': 'pytorch_fx',\n",
      "2024-05-05 19:02:45 [INFO]         'inputs': [\n",
      "2024-05-05 19:02:45 [INFO]         ],\n",
      "2024-05-05 19:02:45 [INFO]         'model_name': '',\n",
      "2024-05-05 19:02:45 [INFO]         'ni_workload_name': 'quantization',\n",
      "2024-05-05 19:02:45 [INFO]         'op_name_dict': {\n",
      "2024-05-05 19:02:45 [INFO]             '.*lm_head': {\n",
      "2024-05-05 19:02:45 [INFO]                 'weight': {\n",
      "2024-05-05 19:02:45 [INFO]                     'dtype': [\n",
      "2024-05-05 19:02:45 [INFO]                         'fp32'\n",
      "2024-05-05 19:02:45 [INFO]                     ]\n",
      "2024-05-05 19:02:45 [INFO]                 }\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             '.*output_layer': {\n",
      "2024-05-05 19:02:45 [INFO]                 'weight': {\n",
      "2024-05-05 19:02:45 [INFO]                     'dtype': [\n",
      "2024-05-05 19:02:45 [INFO]                         'fp32'\n",
      "2024-05-05 19:02:45 [INFO]                     ]\n",
      "2024-05-05 19:02:45 [INFO]                 }\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             '.*embed_out': {\n",
      "2024-05-05 19:02:45 [INFO]                 'weight': {\n",
      "2024-05-05 19:02:45 [INFO]                     'dtype': [\n",
      "2024-05-05 19:02:45 [INFO]                         'fp32'\n",
      "2024-05-05 19:02:45 [INFO]                     ]\n",
      "2024-05-05 19:02:45 [INFO]                 }\n",
      "2024-05-05 19:02:45 [INFO]             }\n",
      "2024-05-05 19:02:45 [INFO]         },\n",
      "2024-05-05 19:02:45 [INFO]         'op_type_dict': {\n",
      "2024-05-05 19:02:45 [INFO]             '.*': {\n",
      "2024-05-05 19:02:45 [INFO]                 'weight': {\n",
      "2024-05-05 19:02:45 [INFO]                     'bits': [\n",
      "2024-05-05 19:02:45 [INFO]                         4\n",
      "2024-05-05 19:02:45 [INFO]                     ],\n",
      "2024-05-05 19:02:45 [INFO]                     'dtype': [\n",
      "2024-05-05 19:02:45 [INFO]                         'int4'\n",
      "2024-05-05 19:02:45 [INFO]                     ],\n",
      "2024-05-05 19:02:45 [INFO]                     'group_size': [\n",
      "2024-05-05 19:02:45 [INFO]                         32\n",
      "2024-05-05 19:02:45 [INFO]                     ],\n",
      "2024-05-05 19:02:45 [INFO]                     'scheme': [\n",
      "2024-05-05 19:02:45 [INFO]                         'sym'\n",
      "2024-05-05 19:02:45 [INFO]                     ],\n",
      "2024-05-05 19:02:45 [INFO]                     'algorithm': [\n",
      "2024-05-05 19:02:45 [INFO]                         'RTN'\n",
      "2024-05-05 19:02:45 [INFO]                     ]\n",
      "2024-05-05 19:02:45 [INFO]                 }\n",
      "2024-05-05 19:02:45 [INFO]             }\n",
      "2024-05-05 19:02:45 [INFO]         },\n",
      "2024-05-05 19:02:45 [INFO]         'outputs': [\n",
      "2024-05-05 19:02:45 [INFO]         ],\n",
      "2024-05-05 19:02:45 [INFO]         'quant_format': 'default',\n",
      "2024-05-05 19:02:45 [INFO]         'quant_level': 'auto',\n",
      "2024-05-05 19:02:45 [INFO]         'recipes': {\n",
      "2024-05-05 19:02:45 [INFO]             'smooth_quant': False,\n",
      "2024-05-05 19:02:45 [INFO]             'smooth_quant_args': {\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'layer_wise_quant': False,\n",
      "2024-05-05 19:02:45 [INFO]             'layer_wise_quant_args': {\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'fast_bias_correction': False,\n",
      "2024-05-05 19:02:45 [INFO]             'weight_correction': False,\n",
      "2024-05-05 19:02:45 [INFO]             'gemm_to_matmul': True,\n",
      "2024-05-05 19:02:45 [INFO]             'graph_optimization_level': None,\n",
      "2024-05-05 19:02:45 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2024-05-05 19:02:45 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2024-05-05 19:02:45 [INFO]             'pre_post_process_quantization': True,\n",
      "2024-05-05 19:02:45 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2024-05-05 19:02:45 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2024-05-05 19:02:45 [INFO]             ],\n",
      "2024-05-05 19:02:45 [INFO]             'dedicated_qdq_pair': False,\n",
      "2024-05-05 19:02:45 [INFO]             'rtn_args': {\n",
      "2024-05-05 19:02:45 [INFO]                 'enable_full_range': True,\n",
      "2024-05-05 19:02:45 [INFO]                 'enable_mse_search': False\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'awq_args': {\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'gptq_args': {\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'teq_args': {\n",
      "2024-05-05 19:02:45 [INFO]             },\n",
      "2024-05-05 19:02:45 [INFO]             'autoround_args': {\n",
      "2024-05-05 19:02:45 [INFO]             }\n",
      "2024-05-05 19:02:45 [INFO]         },\n",
      "2024-05-05 19:02:45 [INFO]         'reduce_range': None,\n",
      "2024-05-05 19:02:45 [INFO]         'TuningCriterion': {\n",
      "2024-05-05 19:02:45 [INFO]             'max_trials': 100,\n",
      "2024-05-05 19:02:45 [INFO]             'objective': [\n",
      "2024-05-05 19:02:45 [INFO]                 'performance'\n",
      "2024-05-05 19:02:45 [INFO]             ],\n",
      "2024-05-05 19:02:45 [INFO]             'strategy': 'basic',\n",
      "2024-05-05 19:02:45 [INFO]             'strategy_kwargs': None,\n",
      "2024-05-05 19:02:45 [INFO]             'timeout': 0\n",
      "2024-05-05 19:02:45 [INFO]         },\n",
      "2024-05-05 19:02:45 [INFO]         'use_bf16': True\n",
      "2024-05-05 19:02:45 [INFO]     }\n",
      "2024-05-05 19:02:45 [INFO] }\n",
      "2024-05-05 19:02:45 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-05-05 19:02:45 [INFO] Pass query framework capability elapsed time: 15.56 ms\n",
      "2024-05-05 19:02:45 [INFO] Do not evaluate the baseline and quantize the model with default configuration.\n",
      "2024-05-05 19:02:45 [INFO] Quantize the model with default config.\n",
      "2024-05-05 19:02:45 [INFO] All algorithms to do: {'RTN'}\n",
      "2024-05-05 19:02:45 [INFO] quantizing with the round-to-nearest algorithm\n",
      "2024-05-05 19:02:56 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-05-05 19:02:56 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 19:02:56 [INFO] | Op Type | Total |  A32W4G32 |  FP32  |\n",
      "2024-05-05 19:02:56 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 19:02:56 [INFO] |  Linear |  225  |    224    |   1    |\n",
      "2024-05-05 19:02:56 [INFO] +---------+-------+-----------+--------+\n",
      "2024-05-05 19:02:56 [INFO] Pass quantize model elapsed time: 10720.7 ms\n",
      "2024-05-05 19:02:56 [INFO] Save tuning history to /autodl-fs/data/auto-testing/intel/nc_workspace/2024-05-05_18-01-59/./history.snapshot.\n",
      "2024-05-05 19:02:56 [INFO] [Strategy] Found the model meets accuracy requirements, ending the tuning process.\n",
      "2024-05-05 19:02:56 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2024-05-05 19:02:56 [INFO] Save deploy yaml to /autodl-fs/data/auto-testing/intel/nc_workspace/2024-05-05_18-01-59/deploy.yaml\n",
      "2024-05-05 19:03:35 [INFO] WeightOnlyQuant done.\n",
      "2024-05-05 19:03:35,037 - root - INFO - Optimized Model loaded.\n"
     ]
    }
   ],
   "source": [
    "from intel_extension_for_transformers.neural_chat import PipelineConfig\n",
    "from intel_extension_for_transformers.neural_chat import build_chatbot\n",
    "from intel_extension_for_transformers.neural_chat import plugins \n",
    "from intel_extension_for_transformers.transformers import RtnConfig\n",
    "from time import time\n",
    "\n",
    "plugins.retrieval.enable=True \n",
    "plugins.retrieval.args['embedding_model'] = \"../../pretrained-model/bge-base-zh-v1.5\" \n",
    "plugins.retrieval.args[\"input_path\"]=\"../data/sample.jsonl\"\n",
    "config = PipelineConfig(\n",
    "    model_name_or_path='Intel/neural-chat-7b-v3-1',\n",
    "    plugins=plugins,\n",
    "    optimization_config=RtnConfig(compute_dtype=\"int8\", weight_dtype=\"int4_fullrange\")\n",
    ")\n",
    "chatbot = build_chatbot(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef522051-5f56-4875-a767-a90b7000f9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 时间:16.13397216796875s\n",
      "The website cnvrg.io was created by Cnvrg, a company focused on simplifying machine learning workflows for data scientists. It is not explicitly mentioned who specifically created it within the team, but they all contribute to its development and growth.\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=False # disable retrieval\n",
    "\n",
    "st = time()\n",
    "response = chatbot.predict(query=\"cnvrg.io 网站是由谁创建的?\") \n",
    "et = time()\n",
    "\n",
    "print(\"predict 时间:{}s\".format(et-st))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9f0c21a-f189-4d8d-8da6-2afae5e62352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149f10df60db416e824257a433a9ff12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:05:59,572 - root - INFO - Chat with QA Agent.\n",
      "/root/miniconda3/envs/itrex-classic/lib/python3.10/site-packages/torch/amp/autocast_mode.py:267: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict 时间:19.162009716033936s\n",
      "网站cnvrg.io由Yochay Ettun和Leah Forkosh Kolben创建。\n"
     ]
    }
   ],
   "source": [
    "plugins.retrieval.enable=True # disable retrieval\n",
    "\n",
    "st = time()\n",
    "response = chatbot.predict(query=\"cnvrg.io 网站是由谁创建的?\") \n",
    "et = time()\n",
    "\n",
    "print(\"predict 时间:{}s\".format(et-st))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcfbbaa-7181-4acc-9545-42beaf16feab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "itrex-classic",
   "language": "python",
   "name": "itrex-classic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
